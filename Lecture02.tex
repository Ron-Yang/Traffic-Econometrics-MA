%#############################################
% New pdflatex format,
% only png, jpg (or svg?) images but positioning now ok
% template in ~/tex/inputs/template_folien.tex
% [TODO now specialized to Vkoem_Ma; make general]
%#############################################


\documentclass[mathserif]{beamer}
%\documentclass[mathserif,handout]{beamer}
%\usepackage{beamerthemeshadow}
\input{$HOME/tex/inputs/defsSkript}
\input{$HOME/tex/inputs/styleVorl}
%\input{../style/defs}
\usepackage{graphicx}


%##############################################################

\begin{document}

\section{2. Linear (Regression) Models}

%##############################################################
\frame{
%##############################################################
\placebox{0.50}{0.50}{
  \figSimple{1.70\textwidth}{figsRegr/regression3dFig.png}}

\makePale{0.85}{0.50}{0.55}{1.20}{1.50}

\placebox{0.50}{0.55} {\parbox{0.6\textwidth}{\bi
  \item[2.1] Flow Chart of the Econometric Method\\[1em]
  \item[2.2] Model Specification
  \bi
   \item[2.2.1] Functional specification
   \item[2.2.2] Statistical specification
   \item[2.2.3] Data specification
  \ei
  \vspace{1em}
  \item[2.3] Ordinary Least Squares (OLS) Estimation
\ei}}

\placebox{0.50}{0.90}{\myheading{Lecture 02: Linear (Regression) Models}}

}

\subsection{2.1 Flow Chart of the Econometric Method}

%##############################################################
\frame{\frametitle{2.1 Flow Chart of the Econometric Method}
%##############################################################

\visible<1>{\placebox{0.302}{0.735}{
\figSimple{0.25\textwidth}{figsRegr/flussdiagRegr02_eng.png}}}

\visible<2>{\placebox{0.5}{0.74}{
\figSimple{0.7\textwidth}{figsRegr/flussdiagRegr03_eng.png}}}

\visible<3>{\placebox{0.5}{0.70}{
\figSimple{0.7\textwidth}{figsRegr/flussdiagRegr04_eng.png}}}

\visible<4>{\placebox{0.525}{0.61}{
\figSimple{0.76\textwidth}{figsRegr/flussdiagRegr05_eng.png}}}

\visible<5>{\placebox{0.515}{0.615}{
\figSimple{0.78\textwidth}{figsRegr/flussdiagRegr06_eng.png}}}

\visible<6>{\placebox{0.515}{0.54}{
\figSimple{0.78\textwidth}{figsRegr/flussdiagRegr07_eng.png}}}

\visible<7>{\placebox{0.515}{0.54}{
\figSimple{0.78\textwidth}{figsRegr/flussdiagRegr08_eng.png}}}

\visible<8>{\placebox{0.515}{0.455}{
\figSimple{0.78\textwidth}{figsRegr/flussdiagRegr09_eng.png}}}

\visible<9>{\placebox{0.515}{0.455}{
\figSimple{0.78\textwidth}{figsRegr/flussdiagRegr10_eng.png}}}



}


\subsection{2.2. Model Specification}

%##############################################################
\frame{\frametitle{2.2. Model Specification}
%##############################################################

As \bfdef{model specification}, we denote the \emph{complete
  structural definition} of the model and its consistency with the
available data. There are three aspects:
\bi
\pause \item \bfdef{Functional specification}: The model's exogenous and
endogenous variables and the functional form in which they appear,
particularly how the original exogenous variables $\tilde{\vec{x}}$
are expressed in terms of linear \bfdef{factors} $x_j=g_j(\tilde{\vec{x}})$
by fixed, generally nonlinear functions $g_j(.)$

\pause \item \bfdef{Statistical specification}: If the model contains
  stochastic elements, e.g., residual ``error'' terms we want to know
  how they are distributed and correlated with each other

\pause \item The \bfdef{data specification} should ensure that the available
  data can be used to analyze the data, for example, sufficient number of data
  sets, check if each set contains all the exogenous and endogenous
  variables
\ei


}

%##############################################################
\frame{\frametitle{WARNING}
%##############################################################

\placebox{0.50}{0.55}{\parbox{0.70\textwidth}{
\maintextbox{0.70\textwidth}{If the
 econometric model is not specified
  correctly, all sorts of problems occur, from mild to nasty:
\bi
\pause \item \green{mild:} the errors are higher than necessary but the results are 
  unbiased and the inferential conclusions correct
\pause \item \orange{medium:} the results are still 
  unbiased but the inferential analysis gives erroneous conclusions
  (higher significance than in reality)
\pause \item \red{nasty:} the results are biased in an unpredictable way
\ei
}}}

\pause \placebox{0.25}{0.15}{\bfred{Junk in, junk out!}}
\pause \placebox{0.75}{0.15}{\parbox{0.25\textwidth}{
\red{There are lies, damned lies, and \bfred{statistics!}}}}



}


 

\subsection{2.2.1 Functional specification}

%##############################################################
\frame{\frametitle{2.2.1 Functional specification 1: relevant factors}
%##############################################################

\vspace{-0.0em}
\fig{0.5\textwidth}{figsRegr/linRegBivar_eng.png}
\vspace{-1.0em}
\fig{0.8\textwidth}{figsRegr/linRegBivar_xz_yz_eng.png}
\vspace{-1em}

{\small
\bi
\item All relevant influencing factors should be taken into account (top),
not one missed (bottom).
\pause \item A violation leads to a bias, i.e., to serious errors:
``junk in, junk out'' 
\ei
}

}

%###################################################
\frame{\frametitle{Functional specification 2: linearity}
%###################################################

\fig{0.7\textwidth}{figsRegr/scatterplot2_eng.png}
\bi
\item The model should be linear which is not fulfilled here.
\pause \item Serious consequences: ``junk in, junk out''.
\pause \item A\emph{change of the independent variable} into several
\bfdef{factors} would be a
solution here,
e.g. $x_0'=1,x_1'=1/x,x_2'=x^2$ or $x_0'=1,x_1'=x,x_2'=x^2$.
\ei
}

%###################################################
\frame{\frametitle{Example: fuel consumption}
%###################################################
Assuming a constant efficiency chemical energy $\to$ mechanical
energy, the required fuel per \unit[100]{km}, $y$, is proportional to the
driving resistance with the contributions
\bi
\item Friction tire-road: contributions independent of the speed
  $\tilde{x}_1$ and proportional to the mass $\tilde{x}_2$.
\pause \item Air drag: proportional to speed squared, $x^2$, and independent
  from mass
\pause \item Gradient: proportional to mass times gradient $\tilde{x}_3$
\ei
\pause In addition, there is a base consumption rate (about
\unit[0.6]{liters/h}) when the car is idling/driving very slowly
$\Rightarrow$ contribution proportional to 1/speed [liters/km=liters/h
  * h/km] $\Rightarrow$ model
\pause
\bdm
y(\vec{x})=\sum_{j=1}^4\beta_jx_j+\epsilon, \quad
x_1=\tilde{x}_2, \quad x_2=\tilde{x}_1^2, \quad
x_3=\tilde{x}_2\tilde{x}_3, \quad
x_4=\frac{1}{\tilde{x}_1}
\edm

}


%###################################################
\frame{\frametitle{Transformation of the endogenous variable}
%###################################################

\visible<1>{\placebox{0.5}{0.55}{
 \figSimple{0.8\textwidth}{figsAllg/dowJones_lin.png}}}
\visible<1>{\placebox{0.5}{0.15}{
 \parbox{0.9\textwidth}{
  Transformation of time $\tilde{x}$ to a factor $x=\exp(\tilde{x})$
  linearizes but fluctuations are not i.i.d (see statistical
  specification below)}}}

\visible<2->{\placebox{0.5}{0.55}{
 \figSimple{0.8\textwidth}{figsAllg/dowJones_log.png}}}
\visible<2>{\placebox{0.5}{0.15}{
 \parbox{0.9\textwidth}{
  Transformation of the endogenous variable $y \to u=\ln(y)$ and
  $x=\tilde{x}$ gives a
  properly specified linear model $u(x)=\beta_0+\beta_1x+\epsilon$,
  $\epsilon \sim \text{i.i.d.}$}}}


}

%###################################################
\frame{\frametitle{Functional specification 3: homogeneity}
%###################################################
%\vspace{2em}
\fig{0.8\textwidth}{figsRegr/scatterplot6_eng.png}
%\vspace{2em}
{\small
\bi
\item If untreated, a discontinuity (``structural break'') in the space of the
exogenous variables leads to a serious bias (``junk ...'')
\pause \item Solution: a dummy
variable with values 0 before, 1 after the break. 
\pause \itemAsk \colAsk{What could possibly cause a structural break?}
\pause \itemAnswer \tiny{\colAnswer{1. new data basis (GDR+West
    Germany $\to$ Germany); 2. Redefinition of a variable (e.g.,
    seriously injured from visit to hospital to overnight visit)}}
\ei
}


}


\subsection{2.2.2 Statistical specification}

%###################################################
\frame{\frametitle{2.2.2 Statistical Specification\\1. the residual
    $\epsilon$ has zero expectation}
%###################################################
\vspace{0em}
\fig{1.0\textwidth}{figsRegr/scatterplot7_eng.png}
\vspace{0em}
\bi
\item The expectation value of the residual deviation should be
  $E(\epsilon)=0$.
\pause\item Least-squared errors (OLS) calibration takes care of this
automatically.  
\pause \item If only differences matter (discrete-choice theory), this
is not relevant.
\ei
}


%###################################################
\frame{\frametitle{Statistical specification 2: homoskedasticity}
%###################################################
\vspace{0em}
\fig{1.0\textwidth}{figsRegr/scatterplot8_eng.png}
\vspace{0em}
\bi
\item The residual $\epsilon$ should be homoscedastic (on the right),
  not heteroscedastic (left). 
\pause \item If this is not satisfied, OLS estimation remains unbiased
but is not efficient (a ``mild'' error).
\pause \item Advanced methods, e.g. weighted OLS, tackle this problem.
\ei
}

%##################################################
\frame{\frametitle{Statistical specification 3: no correlations}
%###################################################
\vspace{0em}
\fig{1.0\textwidth}{figsRegr/scatterplot9_eng.png}
\vspace{0em}
\bi
\item There should be no correlation of $\epsilon$ relative to $x_i$ or $y$
(on the right). The model on the left is mis-specified.
\pause \item Relatively mild consequences 
(model not efficient; underestimation of model errors).
\pause \item Possible solution: identify a missing systematic factor
such as a periodicity.
\ei
}


%###################################################
\frame{\frametitle{Statistical specification 4: Gaussian distribution}
%###################################################

\fig{1.0\textwidth}{figsRegr/scatterplot10_eng.png}
{\small
\bi
\item The residual $\epsilon$ should be Gaussian distributed (right),
not, e.g., bimodally distributed (left).
\pause \item A violation has very mild consequences (OLS remains
unbiased and efficient but the error estimates are wrong).
\pause \item All four statistical specifications can be summarized by
requiring
 \maindm{\epsilon \sim \text{i.i.d.} N(\mu,\sigma^2) \quad 
\text{i.i.d.: \textbf{i}dentical \textbf{i}ndependent 
 \textbf{d}istributions}}
\ei
}

}

\subsubsection{2.2.3 Data specification}
%###################################################
\frame{\frametitle{Data specification 1: enough data}
%###################################################

\bi
\item There must be more data sets (containing all exogenous variables
  and the endogenous variale, each) than model parameters: $n>J+1$
\pause
\item This means, the data should overdetermine the model which is the
  basis for fitting.
\pause
\item If $n=J+1$, the data determine the model exactly, i.e., it can be calibrated to zero residuals
  $\epsilon_i=0$: \emph{overfitting}

\pause \item If there are only a few more data points than parameters, the
  data specification is OK but the estimation errors are big

\ei
}

%###################################################
\frame{\frametitle{Data specification 2: no multi-collinearity}
%###################################################

\fig{0.80\textwidth}{figsRegr/scatterplot4_eng.png}
\vspace{-1em}
\bi
\item A given  exogenous variable  must not be represented as a linear
combination of other exogenous variables. 
\pause \item However, nonperfect
correlations $\neq \pm 1$ are allowed.
\pause \item Nonperfect correlations appear regularly, e.g., price vs
quality
\pause \item If all items of all three specification categories are
fulfilled, the econometric problem satisfies the 
\bfred{Gau\3-Markov assumptions}
\ei
}


%###################################################
\frame{\frametitle{Data specification 2: example}
%###################################################

\vspace{0em}

\fig{0.8\textwidth}{figsRegr/linRegBivar_eng.png}
\bi
\item The normalized demand $y_i$ for public transport in city $i$
  depends on the price $x_{i1}$ and the quality $x_{i2}$ (proxy:
  speed) of the  service.
\pause \item Parameters: intercept $\beta_0$, price sensitivity $\beta_1$,
  appraisal for quality $\beta_2$.
\pause \item Price and quality are correlated but not perfectly so.
\pause \item This model structure is quite generic for products and services.
\ei
}


\subsection{2.3. Ordinary Least Squares Estimation}

%###################################################
\frame{\frametitle{2.3. Ordinary  Least Squares Estimation}
%###################################################
\bi
\pause \item Given is a linear model of the form
\bdm
y(\vec{x})=\vecbeta\tr \vec{x}+\epsilon=\hat{y}(\vec{x})+\epsilon, 
\quad \epsilon \sim i.i.d.\, N(0,\sigma^2)
\edm 
satisfying the Gau\3-Markow specifications,

\pause \item Given is also data in the form of $n$ multidimensional
data points containing all observations and satisfying the
Gau\3-Markow specifications 
as well:
\bdm
\left\{ \vec{p}_i=(x_{i0},..., x_{iJ},y_i)\tr, \quad i=1, ..., n \right\}
\edm

\pause \item Searched for is a parameter estimator $\hatvecbeta$
minimizing the sum of squared errors between data and model prediction
with respect to the parameters:

\maindm{\hatvecbeta = \text{arg min}_{\vecbeta} \,
  S(\vecbeta)}
where
\bdm
S(\vecbeta)=\veceps\tr \veceps=(\vec{y}-\m{X}\vecbeta)\tr
 (\vec{y}-\m{X}\vecbeta).
\edm

\ei

}

%###################################################
\frame{\frametitle{Results}
%###################################################

\bi
\item Ordinary least squares (OLS) estimator:
\maindm{\hatvecbeta =\left(\m{X}\tr\m{X}\right)^{-1}\m{X}\tr\vec{y}}

\pause \item Variance-Covariance matrix of the estimation errors
(provided all the Gau\3-Markow assumptions are satisfied!):

\maindm{\m{V}_{\hatvecbeta}
 = E\left( (\hatvecbeta-\vecbeta)(\hatvecbeta-\vecbeta)\tr\right)
 = 2\sigma^2 \m{H}^{-1}=\hatsig^2 \left(\m{X}\tr\m{X}\right)^{-1}}
where the Hesse matrix $H$ is defined by the second derivatives of the
objective function at the calibration point:
\bdm
H_{jk}=\left. \ablpartmix{S}{\beta_j}{\beta_k}\right|_{\vecbeta=\hatvecbeta}
=2\m{X}\tr\m{X}
\edm

\pause \item Distribution of the normalized estimation errors:
\bdm
\frac{\hatbeta_j-\beta_j}{\sqrt{V_{jj}}} \sim N(0,1)
\edm
\ei
}
 
%###################################################
\frame{\frametitle{Estimation of the residual variance}
%###################################################
The above cannot be applied directly since the residual variance $\sigma^2$ is
unknown and must be estimated by the minimum $S\sub{min}$ of the sum
of squared 
errors: 
\bdm
\hatsig^2=\frac{1}{n-J-1}\sum_i \left(y_i-\hat{y}(\vec{x}_i)\right)^2
 = \frac{S\sub{min}}{n-J-1}
\edm

This results in following \emph{estimated} error statistics:

\bi
\pause \item Estimated variance-covariance matrix:

\maindm{\hat{\m{V}}_{\hatvecbeta}= 2\hatsig^2 \m{H}^{-1}
=\hatsig^2 \left(\m{X}\tr\m{X}\right)^{-1}
}

\pause \item The normalized 
approximate estimation errors are student-t distributed:
\bdm
\frac{\hatbeta_j-\beta_j}{\sqrt{\hat{V}_{jj}}} \sim T(n-1-J)
\edm
\ei
}
 
%###################################################
\frame{\frametitle{Special case 1: No exogenous variables}
%###################################################
\bi
\item Model: $y=\beta_0+\epsilon$
\pause \item System matrix: $\m{X}=(1,1, ..., 1)\tr$
\pause \item OLS estimator: 
\bdma 
\left(\m{X}\tr\m{X}\right)^{-1}=\frac{1}{n}, \quad 
\m{X}\tr \vec{y}=\sum_iy_i=n\bar{y}, &&\\
\hatbeta_0=\hat{\mu}=\left(\m{X}\tr\m{X}\right)^{-1}\m{X}\tr \vec{y}=\bar{y}
\edma
\pause \item Variance:
  $V_{00}=V(\hat{\mu})=\sigma^2\left(\m{X}\tr\m{X}\right)^{-1}
=\frac{\sigma^2}{n}$, \quad
$\hat{V}_{00}=\frac{\hatsig^2}{n}$
\vspace{1em}

\pause \item Distribution of the estimator
 \red{(if $\epsilon \sim i.i.d N(\mu,\sigma^2)$)}
\bdm
\frac{\hatbeta_0-\beta_0}{\sqrt{V_{00}}}
=\frac{\bar{x}-\mu}{\sigma}\ \sqrt{n} \sim N(0,1), \quad
\frac{\bar{x}-\mu}{\hatsig}\ \sqrt{n} \sim T(n-1)
\edm
\ei
}

%###################################################
\frame{\frametitle{Special case 2: Simple linear regression}
%###################################################
\bi
\item Model (with $x_1=x$): $y=\beta_0+\beta_1x+\epsilon$

\pause \item System matrix: 
\bdm \m{X}=\myMatrixTwo{1 & x_1 \\ \vdots & \vdots \\ 1 & x_n},\quad
\m{X}\tr\m{X}=\myMatrixTwo{n & n\bar{x}\\n\bar{x} & \sum x_i^2}
\edm

\pause \item OLS estimator (with $s_x^2=1/n(\sum x_i^2-n\bar{x})$): 
\bdm
\left(\m{X}\tr\m{X}\right)^{-1}
 =\frac{1}{ns_x^2}
\myMatrixTwo{\frac{\sum x_i^2}{n} & -\bar{x} \\ -\bar{x} & 1}, \quad
\m{X}\tr \vec{y}=\myVector{n\bar{y}\\ \sum x_iy_i} 
\edm
\bdma
\hatbeta_1 &=& \left(-\frac{\bar{x}}{ns_x^2}, \frac{1}{ns_x^2}\right)
\myVector{n\bar{y}\\ \sum x_iy_i}
=\frac{\sum_ix_iy_i-n\bar{x}\bar{y}}{\sum x_i^2-n\bar{x}}
=\frac{s_{xy}}{s_x^2}, \\
\hatbeta_0 &=& \bar{y}-\hatbeta_1 \bar{x}
\edma
\ei
}

%###################################################
\frame{\frametitle{Simple linear regression (ctnd)}
%###################################################

\bi
\item Variance-covariance matrix (assuming w/o loss of generality
$\bar{x}=0$): 
\bdm
\m{V}(\hatvecbeta)=\sigma^2 \left(\m{X}\tr\m{X}\right)^{-1}
=\sigma^2 \myMatrixTwo{\frac{1}{n} & 0 \\ 0 & \frac{1}{ns_x^2}}
\edm

\pause \item Variance of the estimator $\hat{y}(x)$ ($x$ is deterministic):
\bdm
V(\hat{y}(x))=V(\hatbeta_0+\hatbeta_1x)
 = V_{00}+x^2  V_{11} +2xV_{01}
 = \frac{\sigma^2}{n}\left(1+\frac{x^2}{s_x^2}\right)
\edm

\pause \item Distribution of the estimator for $y(x)$:
\bdm
\hat{y}(x)\sim N\big(y(x), V(\hat{y}(x))\big)
\edm
If $\sigma^2$ has to be estimated by $\hatsig^2$, the normalized
estimators for $\beta_0$, $\beta_1$ and $y(x)$ are $\sim T(n-2)$.

\ei
}



%###################################################
\frame{\frametitle{Probability density for $\hat{y}(x)$ for simple 
linear regression}
%###################################################

\vspace{-0.5em}
\fig{0.8\textwidth}{figsRegr/regression3dFig.png}
\vspace{-2em}

\bi
\item If the Gau\3-Markov assumptions apply, the model
  estimation errors $\hat{y}(x)-y(x)$ are
  Gaussian distributed
\item The expectation and variance depends on $x$; the standard error
  is hyperbola-shaped.
\ei

}

\end{document}


